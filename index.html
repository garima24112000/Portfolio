<!DOCTYPE HTML>

<html>
	<head>
		<title>Garima Prachi ~ Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<span class="icon fa-gem"></span>
						</div>
						<div class="content">
							<div class="inner">
								<h1>Garima Prachi</h1>
								<p>A passionate and driven Data Science graduate student at SUNY - Stony Brook University, 
								</br>with a strong foundation in Artificial Intelligence, Data Science, Machine Learning and Data Analysis.</p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">Intro</a></li>
								<li><a href="#experience">Experience</a></li>
								<li><a href="#projects">Projects</a></li>
								<li><a href="#blogs">Blogs</a></li>
								<li><a href="https://drive.google.com/file/d/1R4kO76xzKS7vxLnxI9zJaqTmt8tEAA7h" target="_blank">Resume</a></li>
								<li><a href="#contact">Contact</a></li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
						<article id="intro">
							<h2 class="major">Intro</h2>

							<span class="image main" style="display: flex; justify-content: center; background-color: rgba(27, 31, 34, 0.85); padding: 0; margin: 0;">
								<img src="images/pic01.jpeg" alt="Garima Prachi" style="width: 60%; height: auto;" />
							</span>

							<div class="skill-badges">
								<span>AI Systems</span>
								<span>ML</span>
								<span>Data Engineering</span>
								<span>Cloud & MLOps</span>
								<span>SQL</span>
							</div>
						
							<p>
								I am <strong>Garima Prachi</strong>, a graduate student in <strong>Data Science</strong> at Stony Brook University (<strong>GPA 3.76/4.0</strong>) with a strong foundation in <strong>Computer Science and Systems Engineering</strong>. My journey blends analytical rigor with creative problem-solving, driven by a passion for transforming data into insight and deploying <span class="highlight">AI systems at scale.</span>
							</p>
						
							<hr class="section-break" />

							<p>
								Translating this <strong>systems mindset</strong> into practice, I approach AI not just as an isolated modeling task, but as a <strong>comprehensive engineering challenge</strong>, prioritizing data pipelines, orchestration, and reliability. As an <strong>AI Intern at Grant Thornton</strong>, I designed an agentic laytime automation system using Vertex AI (Gemini), reducing manual compliance effort by <strong>85%</strong>. Previously, I spent over a year at <strong>Razorpay</strong> building production payment systems, an experience that grounded my current AI work in rigorous <strong>full-stack development</strong> and <strong>scalable design</strong>. <strong>Currently</strong>, as a <strong>Data Analyst Intern</strong> with <strong>Auxiliary Services Associations at Stony Brook University</strong>, I build automated data pipelines and forecasting dashboards that translate operational data into decision-ready insights.
							</p>

							<p>
								My toolkit spans <strong>Python, SQL, PySpark, PostgreSQL, FAISS, AWS, GCP, PyTorch, TensorFlow/Keras, and XGBoost</strong>, with projects ranging from LLM-powered Multi-Intent Chatbots and Scaling LLMs to RAG-based systems, Invoice Management, and predictive modeling. I enjoy translating ambiguous problem statements into structured, production-ready solutions, whether that means <strong>designing</strong> retrieval pipelines, <strong>optimizing</strong> data workflows, or <strong>evaluating</strong> models beyond surface-level metrics.
							</p>
						
							<hr class="section-break" />
						
							<p>
								Beyond the numbers and models, I am an <span class="highlight">avid learner</span> who thrives in <span class="highlight">collaborative and high-impact environments</span>. There's more to me than code and data. I am a <span class="highlight">creative spirit</span> and a performer, <strong>dancing is my therapy</strong>, and reading <strong>Indian mythology and literature</strong> is my passion.
							</p>
						
							<p>
								I am driven not just by academic success, but also by <span class="highlight">personal growth</span>. Whether it's <span class="highlight">traveling to new places</span> to explore diverse cultures, <span class="highlight">binge-watching thought-provoking series</span>, or <span class="highlight">playing games that sharpen my mind</span>, I bring <strong>enthusiasm and curiosity</strong> to everything I do.
							</p>
						
							<p style="margin-top: 2rem;">
								✨ Let's connect and create something impactful together! Whether it's <span class="highlight">solving data-driven challenges</span> or <span class="highlight">building products that matter</span>, I'm all in.
							</p>
						</article>
						

						<!-- Experience -->
						<article id="experience">
							<h2 class="major">Experience</h2>

							<span class="image main" style="display: flex; justify-content: center;"><img src="images/ASA.png" alt="ASA Data Analyst Intern"/></span>
							
							<h3>Auxiliary Services Association, Stony Brook University</h3>
							<p><em>Data Analyst Intern (Part-Time) | November 2025 - May 2026</em></p>
							<p>As a Data Analyst Intern at Auxiliary Services Association (ASA), I worked on financial analytics, inventory forecasting, and operational audits across retail and finance systems, supporting data-driven decision-making for campus operations.</p>
							
							<ul>
								<li>Developed <strong>inventory and budget forecasting</strong> from Square POS data to project semester-level purchasing needs by category and reorder patterns.</li>
								<li>Built <strong>Power BI dashboards</strong> for monthly, weekly, and daily revenue trends, replacing static PDF reports with executive-ready visuals.</li>
								<li>Designed <strong>dynamic filters and KPI views</strong> (category, location, time) to identify sales spikes, slow-moving inventory, and peak demand.</li>
								<li>Conducted a <strong>5-year OPERS bank account variance analysis</strong> in Oracle Cash Management, identifying unexplained balances and anomalies.</li>
								<li>Performed <strong>payment reconciliation audits</strong> in Oracle ERP, tracing unreconciled checks and resolving rule-matching and configuration gaps.</li>
								<li>Automated <strong>inventory categorization and reconciliation workflows</strong> using Excel VBA, standardizing reporting across 2,000+ retail datasets.</strong>.</li>
								<li>Collaborated with finance, operations, and IT teams to validate assumptions and ensure POS, ERP and accounting data consistency.</li>
							</ul>
						
							<p><strong>Tech Stack:</strong> Power BI | Excel (VBA, Pivot Tables) | Oracle ERP (Cash Management) | Square POS | SQL | Financial Reconciliation | Forecasting & Trend Analysis</p>

							<hr class="section-break" />

							<span class="image main" style="display: flex; justify-content: center;"><img src="images/GT.png" alt="Grant Thornton AI Intern"/></span>
							
							<h3>Grant Thornton Bharat LLP</h3>
							<p><em>Artificial Intelligence Intern | June 2025 - August 2025</em></p>
							<p>As a Summer Intern at Grant Thornton Bharat LLP, I built a Proof-of-Concept for a client to automate laytime and demurrage/despatch calculations in the maritime industry using Generative AI and cloud technologies.</p>
							
							<ul>
								<li><strong>Designed and implemented an AI-powered pipeline</strong> to process documents, extracting structured data with <strong>~90% accuracy</strong>.</li>
								<li><strong>Automated laytime calculation workflows</strong> by interpreting contractual clauses and event timelines, reducing manual effort by <strong>~85%</strong>.</li>
								<li>Developed <strong>human-in-the-loop validation</strong> and audit-traceable reporting, ensuring compliance and transparency for maritime clients.</li>
								<li>Created <strong>Excel and Streamlit dashboards</strong> for real-time laytime/demurrage calculations and end-to-end reporting.</li>
								<li><strong>Integrated multiple OCR and NLP engines</strong> (PyMuPDF, pdfplumber, Tesseract, Vertex AI Gemini) to benchmark extraction accuracy and performance.</li>
								<li>Optimized <strong>Python ETL scripts</strong> to handle large volumes of maritime data and generate Excel deliverables via <strong>openpyxl</strong>.</li>
								<li>Collaborated with cross-functional teams to define KPIs, test assumptions, and deliver production-ready proof of concept.</li>
							</ul>
						
							<p><strong>Tech Stack:</strong> Python | Streamlit | Vertex AI Gemini | Pandas | OCR (PyMuPDF, pdfplumber, Tesseract) | openpyxl | AWS S3 | Excel Automation</p>

							<hr class="section-break" />

							<span class="image main" style="display: flex; justify-content: center;"><img src="images/Razorpay.png" alt="Razorpay Backend Intern"/></span>
							
							<h3>Razorpay Software Pvt Ltd</h3>
							<p><em>Full-Stack Development Intern | May 2022 - July 2023</em></p>
							<p>As a Full-Stack Development Intern at Razorpay, one of India's leading fintech companies, I contributed to backend systems and merchant solutions that directly impacted millions of transactions.</p>
							
							<ul>
								<li><strong>Resolved 50+ production issues</strong> in an Agile Scrum team using JIRA, increasing transaction success rates by <strong>20%</strong> and improving SQL query efficiency by <strong>35%</strong>.</li>
								<li>Received a <strong>Spot Award</strong> for exceptional contributions to backend system optimization and merchant support.</li>
								<li>Implemented instrumentation to enhance transaction monitoring by <strong>40%</strong> across <strong>1,000+ daily transactions</strong>.</li>
								<li>Optimized the <strong>WooCommerce plugin</strong>, increasing test coverage from <strong>0% to 80%</strong> and reducing regression issues by <strong>30%</strong>.</li>
								<li>Enhanced and maintained <strong>3+ Razorpay plugins</strong> (Gravity Forms, PrestaShop, Quick Payments), ensuring <strong>100% compatibility</strong> with platform updates.</li>
								<li>Developed scalable backend services and REST APIs in <strong>PHP</strong> and optimized SQL queries to support high-volume payment systems.</li>
								<li>Streamlined API testing using <strong>Postman</strong> and improved deployment workflows via <strong>Docker</strong>.</li>
							</ul>
						
							<p><strong>Tech Stack:</strong> PHP | SQL (MySQL) | REST APIs | Postman | Docker | JIRA | HTML | CSS | JavaScript</p>
						</article>
						

						<!-- Projects -->
							<article id="projects">
								<h2 class="major">Projects</h2>
								<!-- <span class="image main"><img src="images/pic03.jpg" alt="" /></span>
								<p>Lorem ipsum dolor sit amet, consectetur et adipiscing elit. Praesent eleifend dignissim arcu, at eleifend sapien imperdiet ac. Aliquam erat volutpat. Praesent urna nisi, fringila lorem et vehicula lacinia quam. Integer sollicitudin mauris nec lorem luctus ultrices. Aliquam libero et malesuada fames ac ante ipsum primis in faucibus. Cras viverra ligula sit amet ex mollis mattis lorem ipsum dolor sit amet.</p> -->

								<div class="projects-grid">
									<div id="project11-box" class="project-box" data-project="project11"><span>Scaling Retrieval Systems</span></div>
									<div id="project10-box" class="project-box" data-project="project10"><span>Netflix Recommender System</span></div>
									<div id="project1-box" class="project-box" data-project="project1"><span>Multi-Intent Chatbot</span></div>
									<div id="project2-box" class="project-box" data-project="project2"><span>Spartans - A Retrieval-Augmented AI Dungeon Master</span></div>
									<div id="project5-box" class="project-box" data-project="project5"><span>Invoice Management Tool</span></div>
									<div id="project4-box" class="project-box" data-project="project4"><span>Income Prediction (ML)</span></div>
									<div id="project3-box" class="project-box" data-project="project3"><span>Decoding CO2: Statistical Dive into Global Emissions</span></div>
        							<div id="project6-box" class="project-box" data-project="project6"><span>Image Caption Bot Model</span></div>
									<div id="project7-box" class="project-box" data-project="project7"><span>SMS Spam Detector</span></div>
									<div id="project8-box" class="project-box" data-project="project8"><span>Sentiment Analysis</span></div>
									<div id="project9-box" class="project-box" data-project="project9"><span>Capture Data Changes</span></div>
								</div>



								<!-- Scaling Retrieval System -->
								<div id="project11" class="project-popup">
									<div class="popup-content">
									<span class="close">&times;</span>
									<h3>Scaling Retrieval Systems</h3>
								
									<p>
										Designed and built a <strong>scalable retrieval system</strong> to study how large-scale
										<strong>Retrieval-Augmented Generation (RAG)</strong> pipelines behave under increasing data volume
										and query load, with a focus on performance, latency, and retrieval quality.
									</p>
								
									<p>
										Implemented an end-to-end pipeline covering <strong>data preprocessing</strong>,
										<strong>embedding generation</strong>, and <strong>vector indexing</strong>, experimenting with
										<strong>FAISS</strong> and <strong>Chroma</strong> backends and sharded index strategies to enable
										efficient semantic search across large corpora.
									</p>
								
									<p>
										Evaluated system behavior at scale by benchmarking <strong>query latency</strong>,
										<strong>throughput</strong>, and <strong>retrieval accuracy</strong> under different configurations,
										deriving insights into index design, batching strategies, and tradeoffs between speed and recall
										for production-grade retrieval systems.
									</p>
								
									<p>
										<strong>Tech Stack:</strong> Python | FAISS | Chroma | Spark | Embeddings | Vector Databases | Retrieval-Augmented Generation (RAG)
									</p>
									<p><strong>Project Type:</strong> Academic Project</p>
									<p>
										<a href="https://github.com/garima24112000/Scaling-Retrieval-System" target="_blank" rel="noopener noreferrer">
										View on GitHub
										</a>
									</p>
									</div>
								</div>
  

								<!-- Netflix Recommender System -->
								<div id="project10" class="project-popup">
									<div class="popup-content">
									<span class="close">&times;</span>
									<h3>Netflix Recommender System</h3>
								
									<p>
										Built an end-to-end recommendation system on the <strong>Netflix Prize dataset</strong> (100M+ ratings),
										benchmarking <strong>collaborative filtering</strong> against <strong>deep learning-based recommenders</strong>
										to evaluate performance, scalability, and real-world tradeoffs.
									</p>
									  
									<p>
										Implemented <strong>Spark MLlib (ALS)</strong> for distributed matrix factorization with a focus on
										<strong>memory optimization</strong>, <strong>partitioning</strong>, and <strong>cold-start handling</strong>,
										and built a <strong>FunkSVD (SGD)</strong> pipeline from scratch, accelerating training by
										~<strong>10x using Numba JIT</strong> with bias terms and latent factors on an <strong>HPC environment</strong>.
									</p>
									  
									<p>
										Developed <strong>Neural Collaborative Filtering (NeuMF)</strong> in <strong>PyTorch</strong> (GMF + MLP) using
										<strong>mixed precision training</strong> and <strong>Weights &amp; Biases</strong> tracking, executing large-scale
										experiments on an <strong>HPC cluster with SLURM</strong>. Achieved <strong>RMSE = 0.9327</strong> and
										<strong>MAE = 0.726</strong> on <strong>1.4M</strong> test predictions.
									</p>																			
								
									<p>
										<strong>Tech Stack:</strong> PySpark | Spark MLlib (ALS) | Python | PyTorch | Numba | SLURM (HPC) |
										Weights &amp; Biases | RMSE/MAE Evaluation
									</p>
									<p><strong>Project Type:</strong> Academic Project</p>
									<p>
										<a href="https://github.com/garima24112000/NetflixRecommenderSystem" target="_blank" rel="noopener noreferrer">
										View on GitHub
										</a>
									</p>
									</div>
								</div>
  



								<!-- Project 3 -->
								<div id="project1" class="project-popup">
									<div class="popup-content">
									<span class="close">&times;</span>
									<h3>Multi-Intent Chatbot</h3>
									<p>
										Built an advanced, modular chatbot capable of handling multiple intents across diverse domains by integrating <strong>OpenAI GPT</strong> for natural language understanding and semantic parsing. The system uses a <strong>structured query generator</strong> with slot-filling and semantic mapping to interpret user inputs effectively.
									</p>
									<p>
										Implemented a <strong>PostgreSQL-backed</strong> data layer to store structured domain information and configured a <strong>hybrid caching mechanism</strong> (query hashes and timestamps) to optimize latency. Designed a <strong>Streamlit UI</strong> for users to filter, sort, and export query results, enabling intuitive interaction and exploration.
									</p>
									<p>
										Aggregated and normalized heterogeneous data from <strong>10+ public APIs and web scrapers</strong>, creating a unified knowledge base that supports diverse question domains with high accuracy and efficiency.
									</p>
									<p><strong>Tech Stack:</strong> Python | OpenAI GPT API | PostgreSQL | Streamlit | REST APIs | Web Scraping</p>
									<p><strong>Project Type:</strong> Personal Project</p>
									<p><a href="https://github.com/garima24112000/Multi-Intent-Chatbot" target="_blank">View on GitHub</a></p>
									</div>
								</div>

								<!-- Project 2 -->
								<div id="project2" class="project-popup">
									<div class="popup-content">
									<span class="close">&times;</span>
									<h3>Spartans - A Retrieval-Augmented AI Dungeon Master</h3>
									<p>
										Created <strong>DMRAG (Dungeon Master Retrieval Augmented Generator)</strong>, an AI system that automates the Dungeon Master role for tabletop RPGs like Dungeons & Dragons. This pipeline combines <strong>retrieval-augmented generation</strong> with symbolic rule enforcement to deliver immersive, context-aware adventure narratives  .
									</p>
									<p>
										Built a modular <strong>five-stage RAG pipeline</strong> to ingest and normalize heterogeneous data (rules PDFs, campaign modules, Critical Role transcripts), chunk and embed them using a fine-tuned <strong>BAAI/bge-base sentence transformer</strong>, and retrieve top-k chunks with a <strong>hybrid BM25 + FAISS</strong> strategy  .
									</p>
									<p>
										Fine-tuned <strong>GPT-2 Medium</strong> on 87K+ DM-player exchanges to generate coherent multi-turn responses grounded in rules and lore, while a <strong>game state manager</strong> (OpenAI function-calling) tracks dice rolls, HP changes, and player creation to maintain consistency  .
									</p>
									<p><strong>Tech Stack:</strong> Python | GPT-2 Medium | BAAI/bge-base Embeddings | FAISS | BM25 | OpenAI API | JSONL Pipelines</p>
									<p><strong>Project Type:</strong> Academic Project</p>
									<p><a href="https://drive.google.com/drive/folders/1dT97FjbxxjnbVvROYGZH_oNEyZaIZaUQ?usp=sharing" target="_blank">View Project</a></p>
									</div>
								</div>

								<!-- Project 2 -->
								<div id="project3" class="project-popup">
									<div class="popup-content">
										<span class="close">&times;</span>
										<h3>Decoding CO2: Statistical Dive into Global Emissions</h3>
										<p>
											Designed and implemented a comprehensive statistical analysis and computing pipeline to explore, model, and visualize real-world datasets. The project applied advanced statistical techniques including hypothesis testing, regression analysis, and resampling methods to derive actionable insights.
										</p>
										<p>
											Built the workflow in <strong>R</strong> using <strong>RMarkdown</strong> for reproducibility, integrating data cleaning, exploratory data analysis, and model evaluation. Created interactive visualizations and reports to communicate findings effectively and automate repeatable statistical analyses.
										</p>
										<p><strong>Tech Stack:</strong> R | RMarkdown | ggplot2 | dplyr | Statistical Modeling</p>
										<p><strong>Project Type:</strong> Academic Project</p>
										<p><a href="https://github.com/garima24112000/StatisticalComputingProject" target="_blank">View on GitHub</a></p>
									</div>
								</div>

								<!-- Project 4 -->
								<div id="project4" class="project-popup">
									<div class="popup-content">
									<span class="close">&times;</span>
									<h3>Income Prediction (ML)</h3>
									<p>
										Built a supervised ML pipeline to predict whether an individual's annual income exceeds <strong>$50K</strong> using the <strong>UCI Adult</strong> dataset. The workflow covers data cleaning, missing-value imputation, and <strong>one-hot encoding</strong> for categorical features.
									</p>
									<p>
										Trained and compared multiple models—<strong>Neural Network</strong>, <strong>Logistic Regression</strong>, <strong>Random Forest</strong>, and <strong>XGBoost</strong>—with cross-validation and hyperparameter tuning. Evaluated using <strong>ROC-AUC</strong>, precision/recall, confusion matrix, and feature importance to balance accuracy and fairness.
									</p>
									<p>
										Packaged the process into a reproducible <strong>scikit-learn Pipeline</strong> with experiment tracking and plots for EDA and model diagnostics.
									</p>
									<p><strong>Tech Stack:</strong> Python | Pytorch | scikit-learn | XGBoost | Pandas | NumPy | Matplotlib/Seaborn</p>
									<p><strong>Project Type:</strong> Academic Project</p>
									<p><a href="https://github.com/garima24112000/income-prediction-ml" target="_blank">View on GitHub</a></p>
									</div>
								</div>

								<!-- Project 5 -->
								<div id="project5" class="project-popup">
									<div class="popup-content">
										<span class="close">&times;</span>
										<h3>AI-Enabled FinTech B2B Invoice Management System</h3>
										<p>
											Developed a comprehensive invoice management system tailored for B2B operations, integrating advanced machine learning algorithms to enhance financial processes. The application facilitates efficient handling of accounts receivable, automating invoice processing, and providing predictive analytics for payment behaviors.
										</p>
										<p>
											The frontend is built with <strong>React</strong>, offering a dynamic and responsive user interface. On the backend, <strong>Java</strong> is utilized alongside <strong>JDBC Servlets</strong> to manage database interactions seamlessly. The system also incorporates machine learning models to predict payment delays and optimize cash flow management.
										</p>
										<p><strong>Tech Stack:</strong> Java | JDBC Servlets | React | Machine Learning</p>
										<p><strong>Project Type:</strong> Personal Project</p>
										<p><a href="https://github.com/garima24112000/Invoice-Management-Tool" target="_blank">View on GitHub</a></p>
									</div>
								</div>

								<!-- Project 6 -->
								<div id="project6" class="project-popup">
									<div class="popup-content">
										<span class="close">&times;</span>
										<h3>Image Caption Bot Model</h3>
										<p>
											Developed a deep learning model that generates captions for images by combining computer vision and natural language processing. The model uses a pre-trained <strong>VGG16 CNN</strong> architecture to extract image features and a <strong>Long Short-Term Memory (LSTM)</strong> based sequence generator to produce natural language descriptions.
										</p>
										<p>
											The project includes preprocessing the <strong>Flickr8k dataset</strong> by cleaning and tokenizing captions, creating a word index, and integrating the processed text data with image features. The model is trained end-to-end using <strong>TensorFlow</strong> and <strong>Keras</strong> to produce coherent and contextually accurate captions for unseen images.
										</p>
										<p><strong>Tech Stack:</strong> Python | TensorFlow | Keras | VGG16 (CNN) | LSTM | Flickr8k Dataset</p>
										<p><strong>Project Type:</strong> Personal Project</p>
										<p><a href="https://github.com/garima24112000/Image-Caption-Bot-Model" target="_blank">View on GitHub</a></p>
									</div>
								</div>
							
								<!-- Project 7 -->
								<div id="project7" class="project-popup">
									<div class="popup-content">
										<span class="close">&times;</span>
										<h3>SMS Spam Detector</h3>
										<p>
											A personal project where I built a machine learning model to classify SMS messages as spam or ham using NLP techniques and traditional ML algorithms. The pipeline includes preprocessing steps such as text normalization, tokenization, and stopword removal.
										</p>
										<p>
											Implemented <strong>TF-IDF vectorization</strong> for feature extraction and trained multiple models including <strong>Naive Bayes</strong> and <strong>Logistic Regression</strong> to achieve high accuracy. The project also includes visualizations using WordClouds and Matplotlib to analyze message trends.
										</p>
										<p><strong>Tech Stack:</strong> Python | Scikit-Learn | Pandas | Matplotlib | NLTK | TF-IDF | WordCloud</p>
										<p><strong>Project Type:</strong> Personal Project</p>
										<p><a href="https://github.com/garima24112000/SMS-Spam-Detector" target="_blank">View on GitHub</a></p>
									</div>
								</div>
							
								<!-- Project 8 -->
								<div id="project8" class="project-popup">
									<div class="popup-content">
										<span class="close">&times;</span>
										<h3>Sentiment Analysis</h3>
										<p>
											Developed a deep learning model to perform sentiment classification on movie reviews. The architecture included a word embedding layer utilizing GloVe embeddings to represent text data, an LSTM layer for sequence processing, and a classification layer for predicting sentiment. The model effectively classified reviews as positive or negative based on textual input.
										</p>
										<p><strong>Tech Stack:</strong> Python | PyTorch | GloVe Embeddings | LSTM</p>
										<p><strong>Project Type:</strong> Personal Project</p>
										<p><a href="https://github.com/garima24112000/Sentiment-Analysis" target="_blank">View on GitHub</a></p>
									</div>
								</div>
										
								<!-- Project 9 -->
								<div id="project9" class="project-popup">
									<div class="popup-content">
										<span class="close">&times;</span>
										<h3>Capture Data Changes</h3>
										<p>
											Develop a Python-based utility that tracks and manages data changes across JSON datasets. The system reads historic and current data, compares records, and outputs differences (added/removed/modified fields) in JSON or CSV formats.
										</p>
										<p>
											A lightweight <strong>Flask API</strong> was integrated to expose these functionalities via HTTP endpoints, enabling interaction with the tool through RESTful calls.
										</p>
										<p><strong>Tech Stack:</strong> Python | Flask | JSON</p>
										<p><strong>Project Type:</strong> Group Project</p>
										<p><a href="https://github.com/garima24112000/CaptureDataChanges" target="_blank">View on GitHub</a></p>
									</div>
								</div>	
							</article>


						

						<!-- Blogs -->
						<article id="blogs">
							<h2 class="major">Blogs</h2>
							<!-- <span class="image main"><img src="images/pic03.jpg" alt="" /></span>
							<p>Lorem ipsum dolor sit amet, consectetur et adipiscing elit. Praesent eleifend dignissim arcu, at eleifend sapien imperdiet ac. Aliquam erat volutpat. Praesent urna nisi, fringila lorem et vehicula lacinia quam. Integer sollicitudin mauris nec lorem luctus ultrices. Aliquam libero et malesuada fames ac ante ipsum primis in faucibus. Cras viverra ligula sit amet ex mollis mattis lorem ipsum dolor sit amet.</p> -->

							<div class="projects-grid">
								<a href="https://medium.com/@garimaprachi2411/my-ghc25-experience-lessons-momentum-a-reality-check-as-a-young-woman-in-ai-4b27df2fbed2"
								   target="_blank"
								   rel="noopener noreferrer"
								   class="project-link">
							  
								  <div id="projectb1-box" class="project-box" data-project="projectb1">
									<span>GHC '25</span>
								  </div>
							  
								</a>
							  </div>
						</article>

						<!-- Contact -->
							<article id="contact">
								<h2 class="major">Contact Information</h2> 
								<div class="contact-block">
									<p><strong>University E-mail: </strong><a href="mailto:garima.prachi@stonybrook.edu">garima.prachi@stonybrook.edu</a></p>
									<p><strong>Personal E-mail: </strong><a href="mailto:garimaprachi2411@gmail.com">garimaprachi2411@gmail.com</a></p>
									<p><strong>Phone Number: </strong><a href="tel:+19342463987">+1 (934) 246-3987</a></p>
								</div>

								<ul class="icons">
									<li><a href="https://www.linkedin.com/in/garimaprachi" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
									<li><a href="https://github.com/garima24112000" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
								</ul>								
							</article>
					</div>

				<!-- Footer -->
					<footer id="footer">
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/garimaprachi" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
							<li><a href="https://github.com/garima24112000" class="icon brands fa-github" target="_blank"><span class="label">GitHub</span></a></li>
						</ul>
						<p class="copyright">&copy; Garima Prachi ~ Portfolio</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
